{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the regular expressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = '/Users/elhamali/Documents/Data Projects/clf-climate-label-study/sample-3-recipe-cards.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the PDF with pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataframe to store data\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    # Loop through each page in the PDF\n",
    "    for page in pdf.pages:\n",
    "        # Extract text from the current page\n",
    "        text = page.extract_text()\n",
    "        lines = text.split('\\n')\n",
    "        \n",
    "        # Extract specific variables based on known positions\n",
    "        date = lines[2].split()[1] if len(lines) > 2 else 'Unknown Date'  \n",
    "        meal_type_index = next((i for i, line in enumerate(lines) if 'Meal Type' in line), None)\n",
    "\n",
    "        # Extract variable based on unknown position\n",
    "        if meal_type_index is not None:\n",
    "            meal_type = lines[meal_type_index].split()[-1]\n",
    "            # Assuming the recipe note is the line immediately after meal_type\n",
    "            recipe_note = lines[meal_type_index + 1] if meal_type_index + 1 < len(lines) else 'No Note'\n",
    "        else:\n",
    "            meal_type = 'Unknown Meal Type'\n",
    "            recipe_note = 'No Note'\n",
    "        \n",
    "        # Use regular expressions to match and parse the text\n",
    "        recipe_name_match = re.search(recipe_name_re, text)\n",
    "        yield_match = re.search(yield_re, text)\n",
    "        portions_match = re.search(portions_re, text)\n",
    "        site = 'JHU Nolans on 33rd'\n",
    "        \n",
    "        # Only proceed if all parts were found\n",
    "        if recipe_name_match and yield_match and portions_match:\n",
    "            recipe_name = recipe_name_match.group(1)\n",
    "            yield_amount = yield_match.group(1)\n",
    "            portions, serving_portion_size = portions_match.groups()\n",
    "            \n",
    "            # Find all ingredients\n",
    "            ingredients_matches = re.findall(ingredients_re, text)\n",
    "            \n",
    "            # Process each ingredient match\n",
    "            for ingredient_match in ingredients_matches:\n",
    "                ingredient, portion_used, unit_and_portion_size = ingredient_match\n",
    "                portion_size = \" \".join(unit_and_portion_size.split()[:-1])\n",
    "                unit = unit_and_portion_size.split()[-1]\n",
    "                # Add the details to the data list\n",
    "                data.append({\n",
    "                    'Ingredient': ingredient,\n",
    "                    'Portion Used': portion_used,\n",
    "                    'Portion Size': portion_size,\n",
    "                    'Unit': unit,\n",
    "                    'Recipe Name': recipe_name,\n",
    "                    'Yield': yield_amount,\n",
    "                    'Portions': portions,\n",
    "                    'Serving Portion Size': serving_portion_size,\n",
    "                    'Site': 'JHU Nolans on 33rd',\n",
    "                    'Date': date,\n",
    "                    'Recipe Note': recipe_note,\n",
    "                    'Meal Type': meal_type\n",
    "                })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the data into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the dataframe to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/Users/elhamali/Documents/Data Projects/clf-climate-label-study/recipe-extraction-sheet.xlsx'\n",
    "df.to_excel(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
